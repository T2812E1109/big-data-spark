{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Acciones\n",
    "Una acción en un RDD de Spark es una operación que devuelve un valor al driver del programa. En otras palabras, una acción es una operación que desencadena la ejecución de las transformaciones previas realizadas en el RDD y devuelve el resultado final al programa.\n",
    "\n",
    "Es importante destacar que cada vez que se realiza una acción en un RDD, se activa la evaluación perezosa (lazy evaluation) de las transformaciones previas, lo que significa que Spark solo ejecuta las transformaciones necesarias para generar el resultado de la acción solicitada.\n",
    "\n",
    "Algunos ejemplos de acciones comunes en un RDD son: count, collect, reduce, first, take, ...\n",
    "\n",
    "Existes dos tipos de acción:\n",
    "* **Driver**: Realiza cálculos en el ejecutor y devuelve el resultado al driver.\n",
    "* **Distribuidas**: Se ejcutan en los nodos del clúster."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Acciones\").getOrCreate()\n",
    "\n",
    "sc: SparkContext = spark.sparkContext"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T07:56:22.575583700Z",
     "start_time": "2023-05-12T07:56:04.775815700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Función `reduce` en Spark\n",
    "La función reduce() de Spark es una acción que combina los elementos de un RDD utilizando una función dada y devuelve el resultado al driver del programa. La función reduce() se aplica en un RDD y toma una función de dos argumentos que se utiliza para combinar los elementos del RDD de manera iterativa.\n",
    "\n",
    "La función reduce() comienza combinando los dos primeros elementos del RDD utilizando la función dada. Luego, combina el resultado con el tercer elemento del RDD, y así sucesivamente, hasta que se han combinado todos los elementos del RDD. Finalmente, devuelve el resultado final al driver del programa."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 2, y: 4\n",
      "x: None, y: 6\n",
      "x: None, y: 8\n",
      "x: None, y: 10\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([2, 4, 6, 8, 10])\n",
    "\n",
    "rdd.reduce(lambda x, y: x + y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T07:58:55.148936600Z",
     "start_time": "2023-05-12T07:58:46.846552Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "3840"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.reduce(lambda x, y: x * y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T08:01:26.589969300Z",
     "start_time": "2023-05-12T08:01:18.216895900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Función `count` en Spark\n",
    "La función count() de Spark es una acción que devuelve el número total de elementos en un RDD. Es una operación muy simple pero muy útil que se utiliza comúnmente para contar el número de elementos en un RDD."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "5"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T08:04:33.580359400Z",
     "start_time": "2023-05-12T08:04:25.167284100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Función `collect` en Spark\n",
    "La función collect() de Spark es una acción que devuelve todos los elementos de un RDD al driver del programa como una lista de Python. Se utiliza comúnmente para recuperar los resultados de cálculos en el RDD y trabajar con ellos en el programa cliente. Sin embargo, debe usarse con precaución en RDDs muy grandes para evitar problemas de memoria."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "collect = rdd.collect()\n",
    "print(type(collect))\n",
    "print(collect)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T08:10:00.096458700Z",
     "start_time": "2023-05-12T08:09:59.971397400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Funciones `take`, `max` y `saveAsTextFile` en Spark\n",
    "**take**: La función take() de Spark es una acción que devuelve los primeros n elementos de un RDD como una lista de Python. Se utiliza comúnmente cuando se desea recuperar un pequeño conjunto de elementos de un RDD para su procesamiento y es más eficiente que la función collect().\n",
    "\n",
    "**max**: La función max() de Spark es una acción que devuelve el valor máximo en un RDD. Se puede aplicar a RDDs que contienen valores numéricos o valores alfanuméricos. Si se utiliza en un RDD que contiene valores alfanuméricos, la función max() devuelve el valor máximo basado en el orden lexicográfico de los elementos del RDD.\n",
    "\n",
    "**saveAsTextFile**: La función saveAsTextFile() de Spark es una acción que se utiliza para guardar un RDD en formato de texto plano en un sistema de archivos compatible. Cada partición del RDD se guarda como un archivo separado en el directorio especificado, y el contenido de cada archivo es el resultado de aplicar la función toString() a cada elemento del RDD."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "take = rdd.take(3)\n",
    "print(type(take))\n",
    "print(take)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "rdd_max = rdd.max()\n",
    "print(type(rdd_max))\n",
    "print(rdd_max)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[2, 4, 6]\n",
      "<class 'int'>\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "og_num_partitions = rdd.getNumPartitions()\n",
    "rdd_5_partitions = rdd.coalesce(5)\n",
    "rdd_5_partitions.saveAsTextFile(\"../../foo\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T08:20:23.131513100Z",
     "start_time": "2023-05-12T08:19:57.259899100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
